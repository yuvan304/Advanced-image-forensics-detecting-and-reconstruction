{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":115146,"sourceType":"datasetVersion","datasetId":59500},{"sourceId":2065466,"sourceType":"datasetVersion","datasetId":1237999}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:06.998644Z","iopub.execute_input":"2024-05-23T13:15:06.999423Z","iopub.status.idle":"2024-05-23T13:15:07.012464Z","shell.execute_reply.started":"2024-05-23T13:15:06.999353Z","shell.execute_reply":"2024-05-23T13:15:07.011089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.016123Z","iopub.execute_input":"2024-05-23T13:15:07.017181Z","iopub.status.idle":"2024-05-23T13:15:07.075699Z","shell.execute_reply.started":"2024-05-23T13:15:07.017135Z","shell.execute_reply":"2024-05-23T13:15:07.073485Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-05-23 13:15:07.041109: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/api/tf2_enable\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3407825148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m _tf2_gauge = _monitoring.BoolGauge(\n\u001b[0;32m--> 122\u001b[0;31m     '/tensorflow/api/tf2_enable', 'Environment variable TF2_BEHAVIOR is set\".')\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0m_tf2_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, description, *labels)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \"\"\"\n\u001b[1;32m    356\u001b[0m     super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,\n\u001b[0;32m--> 357\u001b[0;31m                                     len(labels), name, description, *labels)\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m           self._metric_name, len(self._metric_methods)))\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."],"ename":"AlreadyExistsError","evalue":"Another metric with the same name already exists.","output_type":"error"}]},{"cell_type":"code","source":"#from keras.callbacks import EarlyS\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.076542Z","iopub.status.idle":"2024-05-23T13:15:07.077024Z","shell.execute_reply.started":"2024-05-23T13:15:07.076772Z","shell.execute_reply":"2024-05-23T13:15:07.076797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageChops, ImageEnhance\nimport os\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.078682Z","iopub.status.idle":"2024-05-23T13:15:07.079133Z","shell.execute_reply.started":"2024-05-23T13:15:07.078883Z","shell.execute_reply":"2024-05-23T13:15:07.078928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    ela_filename = 'temp_ela.png'\n    \n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n    \n    ela_image = ImageChops.difference(image, temp_image)\n    \n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n    \n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.080779Z","iopub.status.idle":"2024-05-23T13:15:07.081242Z","shell.execute_reply.started":"2024-05-23T13:15:07.081040Z","shell.execute_reply":"2024-05-23T13:15:07.081063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nclass Config:\n    CASIA1 = \"../input/casia-dataset/CASIA1\"\n    CASIA2 = \"../input/casia-dataset/CASIA2\"\n    autotune = tf.data.experimental.AUTOTUNE\n    epochs = 30\n    batch_size = 32\n    lr = 1e-3\n    name = 'xception'\n    n_labels = 2\n    image_size = (224, 224)\n    decay = 1e-6\n    momentum = 0.95\n    nesterov = False","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.082844Z","iopub.status.idle":"2024-05-23T13:15:07.083448Z","shell.execute_reply.started":"2024-05-23T13:15:07.083229Z","shell.execute_reply":"2024-05-23T13:15:07.083255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_ela_cv(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    SCALE = 15\n    orig_img = cv2.imread(path)\n    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n    \n    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n\n    # read compressed image\n    compressed_img = cv2.imread(temp_filename)\n\n    # get absolute difference between img1 and img2 and multiply by scale\n    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n    return diff","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.084526Z","iopub.status.idle":"2024-05-23T13:15:07.084920Z","shell.execute_reply.started":"2024-05-23T13:15:07.084716Z","shell.execute_reply":"2024-05-23T13:15:07.084736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_sample(path, extension=None):\n    if extension:\n        items = Path(path).glob(f'*.{extension}')\n    else:\n        items = Path(path).glob(f'*')\n        \n    items = list(items)\n        \n    p = random.choice(items)\n    return p.as_posix()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.086576Z","iopub.status.idle":"2024-05-23T13:15:07.087006Z","shell.execute_reply.started":"2024-05-23T13:15:07.086775Z","shell.execute_reply":"2024-05-23T13:15:07.086796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test on a Authentic image","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom os.path import join, exists, isdir\nfrom pathlib import Path\nimport random\np = join(Config.CASIA2, 'Au/')\np = random_sample(p)\norig = cv2.imread(p)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0\ninit_val = 100\ncolumns = 3\nrows = 3\n\nfig=plt.figure(figsize=(15, 10))\nfor i in range(1, columns*rows +1):\n    quality=init_val - (i-1) * 3\n    img = compute_ela_cv(path=p, quality=quality)\n    if i == 1:\n        img = orig.copy()\n    ax = fig.add_subplot(rows, columns, i) \n    ax.title.set_text(f'q: {quality}')\n    plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.088110Z","iopub.status.idle":"2024-05-23T13:15:07.088887Z","shell.execute_reply.started":"2024-05-23T13:15:07.088668Z","shell.execute_reply":"2024-05-23T13:15:07.088693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test on a tampered fake image","metadata":{}},{"cell_type":"code","source":"p = join(Config.CASIA2, 'Tp/')\np = random_sample(p)\norig = cv2.imread(p)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0\ninit_val = 100\ncolumns = 3\nrows = 3\n\nfig=plt.figure(figsize=(15, 10))\nfor i in range(1, columns*rows +1):\n    quality=init_val - (i-1) * 3\n    img = compute_ela_cv(path=p, quality=quality)\n    if i == 1:\n        img = orig.copy()\n    ax = fig.add_subplot(rows, columns, i) \n    ax.title.set_text(f'q: {quality}')\n    plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.090023Z","iopub.status.idle":"2024-05-23T13:15:07.091028Z","shell.execute_reply.started":"2024-05-23T13:15:07.090645Z","shell.execute_reply":"2024-05-23T13:15:07.090686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image_path = '../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg'\nImage.open(real_image_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.235848Z","iopub.execute_input":"2024-05-23T13:15:07.237234Z","iopub.status.idle":"2024-05-23T13:15:07.266270Z","shell.execute_reply.started":"2024-05-23T13:15:07.237181Z","shell.execute_reply":"2024-05-23T13:15:07.261668Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1701665341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreal_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"],"ename":"NameError","evalue":"name 'Image' is not defined","output_type":"error"}]},{"cell_type":"code","source":"convert_to_ela_image(real_image_path, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.267252Z","iopub.status.idle":"2024-05-23T13:15:07.267787Z","shell.execute_reply.started":"2024-05-23T13:15:07.267507Z","shell.execute_reply":"2024-05-23T13:15:07.267532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '../input/casia-dataset/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nImage.open(fake_image_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.269607Z","iopub.status.idle":"2024-05-23T13:15:07.270100Z","shell.execute_reply.started":"2024-05-23T13:15:07.269851Z","shell.execute_reply":"2024-05-23T13:15:07.269876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(fake_image_path, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.271698Z","iopub.status.idle":"2024-05-23T13:15:07.272173Z","shell.execute_reply.started":"2024-05-23T13:15:07.271952Z","shell.execute_reply":"2024-05-23T13:15:07.271978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DENOISING REAL IMAGE","metadata":{}},{"cell_type":"code","source":"# Color-image denoising\nfrom skimage.restoration import (denoise_wavelet,estimate_sigma)\nfrom skimage.util import random_noise\n# from sklearn.metrics import peak_signal_noise_ratio\nimport skimage.io\n\nimg_r1=skimage.io.imread('../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg')\nimg_r=skimage.img_as_float(img_r1) #converting image as float\n\nsigma_est=estimate_sigma(img_r,channel_axis=True,average_sigmas=True)  #Noise estimation\n# Denoising using Bayes\nimg_bayes=denoise_wavelet(img_r,method='BayesShrink',mode='soft',wavelet_levels=3,\n                          wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n\n#Denoising using Visushrink\nimg_visushrink=denoise_wavelet(img_r,method='VisuShrink',mode='soft',sigma=sigma_est/3,wavelet_levels=5,\n                               wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.274712Z","iopub.status.idle":"2024-05-23T13:15:07.275575Z","shell.execute_reply.started":"2024-05-23T13:15:07.275333Z","shell.execute_reply":"2024-05-23T13:15:07.275362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\npsnr_noisy = cv2.PSNR(img_r,img_r)\npsnr_noisy","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.277004Z","iopub.status.idle":"2024-05-23T13:15:07.277465Z","shell.execute_reply.started":"2024-05-23T13:15:07.277248Z","shell.execute_reply":"2024-05-23T13:15:07.277274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psnr_bayes = cv2.PSNR(img_r,img_bayes)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.278725Z","iopub.status.idle":"2024-05-23T13:15:07.279183Z","shell.execute_reply.started":"2024-05-23T13:15:07.278971Z","shell.execute_reply":"2024-05-23T13:15:07.278994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psnr_visu = cv2.PSNR(img_r,img_visushrink)\npsnr_visu","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.280661Z","iopub.status.idle":"2024-05-23T13:15:07.281148Z","shell.execute_reply.started":"2024-05-23T13:15:07.280923Z","shell.execute_reply":"2024-05-23T13:15:07.280953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting images\nplt.figure(figsize=(30,30))\n\nplt.subplot(2,2,1)\nplt.imshow(img_r1,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,2)\nplt.imshow(img_r,cmap=plt.cm.gray)\nplt.title('Noisy Image',fontsize=30)\n\nplt.subplot(2,2,3)\nplt.imshow(img_bayes,cmap=plt.cm.gray)\nplt.title('Denoising using Bayes',fontsize=30)\n\nplt.subplot(2,2,4)\nplt.imshow(img_visushrink,cmap=plt.cm.gray)\nplt.title('Denoising using Visushrink',fontsize=30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.282603Z","iopub.status.idle":"2024-05-23T13:15:07.283105Z","shell.execute_reply.started":"2024-05-23T13:15:07.282845Z","shell.execute_reply":"2024-05-23T13:15:07.282876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('PSNR[Original vs. Noisy Image]', psnr_noisy)\nprint('PSNR[Original vs. Denoised(VisuShrink)]', psnr_visu)\nprint('PSNR[Original vs. Denoised(Bayes)]', psnr_bayes)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.284413Z","iopub.status.idle":"2024-05-23T13:15:07.284844Z","shell.execute_reply.started":"2024-05-23T13:15:07.284634Z","shell.execute_reply":"2024-05-23T13:15:07.284658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DENOISING FAKE IMAGE","metadata":{}},{"cell_type":"code","source":"# Color-image denoising\nfrom skimage.restoration import (denoise_wavelet,estimate_sigma)\nfrom skimage.util import random_noise\n# from sklearn.metrics import peak_signal_noise_ratio\nimport skimage.io\n\nimg_f=skimage.io.imread('../input/casia-dataset/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg')\nimg_f=skimage.img_as_float(img_f) #converting image as float\n\nsigma=0.35 #noise\nimgn=random_noise(img_f,var=sigma**2) # adding noise\n\nsigma_est=estimate_sigma(img_f,channel_axis=True,average_sigmas=True)  #Noise estimation\n\n# Denoising using Bayes\nimg_bayes=denoise_wavelet(img_f,method='BayesShrink',mode='soft',wavelet_levels=3,\n                          wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n\n\n#Denoising using Visushrink\nimg_visushrink=denoise_wavelet(img_f,method='VisuShrink',mode='soft',sigma=sigma_est/3,wavelet_levels=5,\n                               wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.288687Z","iopub.status.idle":"2024-05-23T13:15:07.289253Z","shell.execute_reply.started":"2024-05-23T13:15:07.289006Z","shell.execute_reply":"2024-05-23T13:15:07.289036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\npsnr_noisy = cv2.PSNR(img_f,img_f)\npsnr_noisy","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.291931Z","iopub.status.idle":"2024-05-23T13:15:07.292443Z","shell.execute_reply.started":"2024-05-23T13:15:07.292215Z","shell.execute_reply":"2024-05-23T13:15:07.292243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psnr_bayes = cv2.PSNR(img_f,img_bayes)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.294229Z","iopub.status.idle":"2024-05-23T13:15:07.295173Z","shell.execute_reply.started":"2024-05-23T13:15:07.294888Z","shell.execute_reply":"2024-05-23T13:15:07.294940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psnr_visu = cv2.PSNR(img_f,img_visushrink)\npsnr_visu","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.296319Z","iopub.status.idle":"2024-05-23T13:15:07.297273Z","shell.execute_reply.started":"2024-05-23T13:15:07.297027Z","shell.execute_reply":"2024-05-23T13:15:07.297059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting images\nplt.figure(figsize=(30,30))\n\nplt.subplot(2,2,1)\nplt.imshow(img_f,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,2)\nplt.imshow(img_f,cmap=plt.cm.gray)\nplt.title('Noisy Image',fontsize=30)\n\nplt.subplot(2,2,3)\nplt.imshow(img_bayes,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,4)\nplt.imshow(img_visushrink,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.299144Z","iopub.status.idle":"2024-05-23T13:15:07.299599Z","shell.execute_reply.started":"2024-05-23T13:15:07.299386Z","shell.execute_reply":"2024-05-23T13:15:07.299411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('PSNR[Original vs. Noisy Image]', psnr_noisy)\nprint('PSNR[Original vs. Denoised(VisuShrink)]', psnr_visu)\nprint('PSNR[Original vs. Denoised(Bayes)]', psnr_bayes)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.301293Z","iopub.status.idle":"2024-05-23T13:15:07.301732Z","shell.execute_reply.started":"2024-05-23T13:15:07.301517Z","shell.execute_reply":"2024-05-23T13:15:07.301541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Color-image denoising\nfrom skimage.restoration import (denoise_wavelet,estimate_sigma)\nfrom skimage.util import random_noise\n# from sklearn.metrics import peak_signal_noise_ratio\nimport skimage.io","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.303750Z","iopub.status.idle":"2024-05-23T13:15:07.304650Z","shell.execute_reply.started":"2024-05-23T13:15:07.304396Z","shell.execute_reply":"2024-05-23T13:15:07.304427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denoise_img(img):\n    #img=skimage.io.imread('../input/casia-dataset/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg')\n    img=skimage.img_as_float(img_f) #converting image as float\n\n\n    sigma_est=estimate_sigma(img,multichannel=True,average_sigmas=True)  #Noise estimation\n\n    # Denoising using Bayes\n    img_bayes=denoise_wavelet(img,method='BayesShrink',mode='soft',wavelet_levels=3,\n                          wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n\n\n    #Denoising using Visushrink\n    img_visushrink=denoise_wavelet(img,method='VisuShrink',mode='soft',sigma=sigma_est/3,wavelet_levels=5,\n    wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n    return img_bayes ","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.306418Z","iopub.status.idle":"2024-05-23T13:15:07.306883Z","shell.execute_reply.started":"2024-05-23T13:15:07.306657Z","shell.execute_reply":"2024-05-23T13:15:07.306681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (128, 128)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.308601Z","iopub.status.idle":"2024-05-23T13:15:07.309077Z","shell.execute_reply.started":"2024-05-23T13:15:07.308825Z","shell.execute_reply":"2024-05-23T13:15:07.308847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_image(image_path):\n    return np.array(convert_to_ela_image(image_path, 91).resize(image_size)).flatten() / 255.0","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.311299Z","iopub.status.idle":"2024-05-23T13:15:07.311736Z","shell.execute_reply.started":"2024-05-23T13:15:07.311527Z","shell.execute_reply":"2024-05-23T13:15:07.311551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [] # ELA converted images\nY = [] # 0 for fake, 1 for real","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.313537Z","iopub.status.idle":"2024-05-23T13:15:07.314099Z","shell.execute_reply.started":"2024-05-23T13:15:07.313790Z","shell.execute_reply":"2024-05-23T13:15:07.313815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\npath = '../input/casia-dataset/CASIA2/Au/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(1)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nrandom.shuffle(X)\nX = X[:2100]\nY = Y[:2100]\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.315289Z","iopub.status.idle":"2024-05-23T13:15:07.315751Z","shell.execute_reply.started":"2024-05-23T13:15:07.315520Z","shell.execute_reply":"2024-05-23T13:15:07.315543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/casia-dataset/CASIA2/Tp/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(0)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.317669Z","iopub.status.idle":"2024-05-23T13:15:07.318172Z","shell.execute_reply.started":"2024-05-23T13:15:07.317942Z","shell.execute_reply":"2024-05-23T13:15:07.317969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX = np.array(X)\nY = to_categorical(Y, 2)\nX = X.reshape(-1, 128, 128, 3)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.320965Z","iopub.status.idle":"2024-05-23T13:15:07.321408Z","shell.execute_reply.started":"2024-05-23T13:15:07.321200Z","shell.execute_reply":"2024-05-23T13:15:07.321222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\nX = X.reshape(-1,1,1,1)\nprint(len(X_train), len(Y_train))\nprint(len(X_val), len(Y_val))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.323306Z","iopub.status.idle":"2024-05-23T13:15:07.324063Z","shell.execute_reply.started":"2024-05-23T13:15:07.323771Z","shell.execute_reply":"2024-05-23T13:15:07.323804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = 'softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.325517Z","iopub.status.idle":"2024-05-23T13:15:07.326012Z","shell.execute_reply.started":"2024-05-23T13:15:07.325756Z","shell.execute_reply":"2024-05-23T13:15:07.325782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.329337Z","iopub.status.idle":"2024-05-23T13:15:07.329839Z","shell.execute_reply.started":"2024-05-23T13:15:07.329603Z","shell.execute_reply":"2024-05-23T13:15:07.329630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import optimizers\nmodel.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.331727Z","iopub.status.idle":"2024-05-23T13:15:07.332241Z","shell.execute_reply.started":"2024-05-23T13:15:07.332001Z","shell.execute_reply":"2024-05-23T13:15:07.332028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 24\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.334084Z","iopub.status.idle":"2024-05-23T13:15:07.334560Z","shell.execute_reply.started":"2024-05-23T13:15:07.334335Z","shell.execute_reply":"2024-05-23T13:15:07.334360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\noptimizer = Adam(lr = init_lr, decay = init_lr/epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.477643Z","iopub.execute_input":"2024-05-23T13:15:07.478209Z","iopub.status.idle":"2024-05-23T13:15:07.504545Z","shell.execute_reply.started":"2024-05-23T13:15:07.478151Z","shell.execute_reply":"2024-05-23T13:15:07.500288Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1742359010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_lr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"],"ename":"NameError","evalue":"name 'Adam' is not defined","output_type":"error"}]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor = 'val_acc',\n                              min_delta = 0,\n                              patience = 2,\n                              verbose = 0,\n                              mode = 'auto')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.505754Z","iopub.status.idle":"2024-05-23T13:15:07.506677Z","shell.execute_reply.started":"2024-05-23T13:15:07.506347Z","shell.execute_reply":"2024-05-23T13:15:07.506399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nx_train2 = np.array(X_train, copy=True) \ny_train2 = np.array(Y_train, copy=True) \n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    fill_mode='nearest',\n    validation_split = 0.2\n    )\n\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\n\ndatagen.fit(X_train)\n\nprint(type(X_train))\n\n#earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='min')\n\nvalidation_generator = datagen.flow(x_train2, y_train2, batch_size=32, subset='validation')\ntrain_generator = datagen.flow(x_train2, y_train2,batch_size=32, subset='training')\n\n\n\n\n# # fits the model on batches with real-time data augmentation:\nhistory = model.fit_generator(train_generator, epochs=epochs, validation_data = (X_val,Y_val), verbose = 1,callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.508038Z","iopub.status.idle":"2024-05-23T13:15:07.508656Z","shell.execute_reply.started":"2024-05-23T13:15:07.508449Z","shell.execute_reply":"2024-05-23T13:15:07.508472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.509724Z","iopub.status.idle":"2024-05-23T13:15:07.510205Z","shell.execute_reply.started":"2024-05-23T13:15:07.509982Z","shell.execute_reply":"2024-05-23T13:15:07.510007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train,\n                 Y_train,\n                 batch_size = batch_size,\n                 epochs = epochs,\n                validation_data = (X_val, Y_val),\n                callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.512016Z","iopub.status.idle":"2024-05-23T13:15:07.512463Z","shell.execute_reply.started":"2024-05-23T13:15:07.512243Z","shell.execute_reply":"2024-05-23T13:15:07.512266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_casia_run1.h5')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.514367Z","iopub.status.idle":"2024-05-23T13:15:07.514829Z","shell.execute_reply.started":"2024-05-23T13:15:07.514613Z","shell.execute_reply":"2024-05-23T13:15:07.514639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation acc\n           uracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.516428Z","iopub.status.idle":"2024-05-23T13:15:07.517311Z","shell.execute_reply.started":"2024-05-23T13:15:07.517056Z","shell.execute_reply":"2024-05-23T13:15:07.517088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.519471Z","iopub.status.idle":"2024-05-23T13:15:07.520524Z","shell.execute_reply.started":"2024-05-23T13:15:07.520281Z","shell.execute_reply":"2024-05-23T13:15:07.520309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.521829Z","iopub.status.idle":"2024-05-23T13:15:07.522730Z","shell.execute_reply.started":"2024-05-23T13:15:07.522499Z","shell.execute_reply":"2024-05-23T13:15:07.522528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['fake', 'real']","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.524756Z","iopub.status.idle":"2024-05-23T13:15:07.525653Z","shell.execute_reply.started":"2024-05-23T13:15:07.525313Z","shell.execute_reply":"2024-05-23T13:15:07.525351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image_path = '../input/casia-dataset/CASIA2/Au/Au_ani_00040.jpg'\nImage.open(real_image_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.527483Z","iopub.status.idle":"2024-05-23T13:15:07.528129Z","shell.execute_reply.started":"2024-05-23T13:15:07.527791Z","shell.execute_reply":"2024-05-23T13:15:07.527824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = prepare_image(real_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.529420Z","iopub.status.idle":"2024-05-23T13:15:07.530050Z","shell.execute_reply.started":"2024-05-23T13:15:07.529719Z","shell.execute_reply":"2024-05-23T13:15:07.529752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/CASIA2/Tp/Tp_D_NRD_S_N_ani00041_ani00040_00161.tif'\nImage.open(fake_image_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.531668Z","iopub.status.idle":"2024-05-23T13:15:07.533168Z","shell.execute_reply.started":"2024-05-23T13:15:07.532818Z","shell.execute_reply":"2024-05-23T13:15:07.532854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = prepare_image(fake_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.534431Z","iopub.status.idle":"2024-05-23T13:15:07.535046Z","shell.execute_reply.started":"2024-05-23T13:15:07.534724Z","shell.execute_reply":"2024-05-23T13:15:07.534755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_image = os.listdir('../input/casia-dataset/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in fake_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('../input/casia-dataset/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.536729Z","iopub.status.idle":"2024-05-23T13:15:07.537332Z","shell.execute_reply.started":"2024-05-23T13:15:07.537024Z","shell.execute_reply":"2024-05-23T13:15:07.537057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.538942Z","iopub.status.idle":"2024-05-23T13:15:07.539543Z","shell.execute_reply.started":"2024-05-23T13:15:07.539229Z","shell.execute_reply":"2024-05-23T13:15:07.539261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image = os.listdir('../input/casia-dataset/CASIA2/Au/')\ncorrect_r = 0\ntotal_r = 0\nfor file_name in real_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        real_image_path = os.path.join('../input/casia-dataset/CASIA2/Au/', file_name)\n        image = prepare_image(real_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total_r += 1\n        if y_pred_class == 1:\n            correct_r += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.541652Z","iopub.status.idle":"2024-05-23T13:15:07.542272Z","shell.execute_reply.started":"2024-05-23T13:15:07.541960Z","shell.execute_reply":"2024-05-23T13:15:07.541994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct += correct_r\ntotal += total_r\nprint(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.543852Z","iopub.status.idle":"2024-05-23T13:15:07.544460Z","shell.execute_reply.started":"2024-05-23T13:15:07.544163Z","shell.execute_reply":"2024-05-23T13:15:07.544195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path1 = '/kaggle/input/casia-dataset/CASIA1/Au/Au_ani_0028.jpg'\nImage.open(image_path1)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.546128Z","iopub.status.idle":"2024-05-23T13:15:07.548197Z","shell.execute_reply.started":"2024-05-23T13:15:07.547884Z","shell.execute_reply":"2024-05-23T13:15:07.547936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = prepare_image(image_path1)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.549469Z","iopub.status.idle":"2024-05-23T13:15:07.549888Z","shell.execute_reply.started":"2024-05-23T13:15:07.549676Z","shell.execute_reply":"2024-05-23T13:15:07.549697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path2 = '/kaggle/input/casia-dataset/CASIA1/Sp/Sp_D_NNN_A_ani0028_pla0007_0284.jpg'\nImage.open(image_path2)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.551833Z","iopub.status.idle":"2024-05-23T13:15:07.552465Z","shell.execute_reply.started":"2024-05-23T13:15:07.552154Z","shell.execute_reply":"2024-05-23T13:15:07.552188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = prepare_image(image_path2)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.554104Z","iopub.status.idle":"2024-05-23T13:15:07.554706Z","shell.execute_reply.started":"2024-05-23T13:15:07.554391Z","shell.execute_reply":"2024-05-23T13:15:07.554423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(image_path1, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.556791Z","iopub.status.idle":"2024-05-23T13:15:07.557294Z","shell.execute_reply.started":"2024-05-23T13:15:07.557062Z","shell.execute_reply":"2024-05-23T13:15:07.557091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_1_ELA=convert_to_ela_image(image_path1, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.558947Z","iopub.status.idle":"2024-05-23T13:15:07.559366Z","shell.execute_reply.started":"2024-05-23T13:15:07.559167Z","shell.execute_reply":"2024-05-23T13:15:07.559189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(image_path2, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.562133Z","iopub.status.idle":"2024-05-23T13:15:07.562591Z","shell.execute_reply.started":"2024-05-23T13:15:07.562371Z","shell.execute_reply":"2024-05-23T13:15:07.562395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_2_ELA=convert_to_ela_image(image_path2, 91)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.563723Z","iopub.status.idle":"2024-05-23T13:15:07.564197Z","shell.execute_reply.started":"2024-05-23T13:15:07.563963Z","shell.execute_reply":"2024-05-23T13:15:07.563996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ela_image = ImageChops.difference(image_1_ELA, image_2_ELA)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.565319Z","iopub.status.idle":"2024-05-23T13:15:07.565730Z","shell.execute_reply.started":"2024-05-23T13:15:07.565527Z","shell.execute_reply":"2024-05-23T13:15:07.565549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ela_image","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.566945Z","iopub.status.idle":"2024-05-23T13:15:07.567362Z","shell.execute_reply.started":"2024-05-23T13:15:07.567159Z","shell.execute_reply":"2024-05-23T13:15:07.567181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.568592Z","iopub.status.idle":"2024-05-23T13:15:07.569044Z","shell.execute_reply.started":"2024-05-23T13:15:07.568799Z","shell.execute_reply":"2024-05-23T13:15:07.568822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_manipulated_region(ela, threshold=50):\n    mask = np.array(ela) > threshold\n\n    # Find the bounding box of the masked region\n    if np.any(mask):\n        coords = np.argwhere(mask)\n        return coords\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.570260Z","iopub.status.idle":"2024-05-23T13:15:07.570676Z","shell.execute_reply.started":"2024-05-23T13:15:07.570470Z","shell.execute_reply":"2024-05-23T13:15:07.570492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_pixels_white(img, white_coords):\n    width, height = img.size\n    black_img = Image.new('RGB', (width, height), color='black')\n    img_arr = np.array(img)\n    black_arr = np.array(black_img)\n    for coord in white_coords:\n        x, y, z = coord\n        black_arr[x,y,:] = [255,255,255]\n    mask = np.all(black_arr == [255,255,255], axis=-1)\n    img_arr[mask] = [255,255,255]\n    new_img = Image.fromarray(img_arr)\n    return new_img","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.571793Z","iopub.status.idle":"2024-05-23T13:15:07.572235Z","shell.execute_reply.started":"2024-05-23T13:15:07.572028Z","shell.execute_reply":"2024-05-23T13:15:07.572051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if y_pred_class==0:\n    ela=convert_to_ela_image(image_path2,91)\n    coords=find_manipulated_region(ela)\n    modify_boundary=make_pixels_white(ela,coords)\n    modify_boundary.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.573568Z","iopub.status.idle":"2024-05-23T13:15:07.574011Z","shell.execute_reply.started":"2024-05-23T13:15:07.573775Z","shell.execute_reply":"2024-05-23T13:15:07.573797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, LeakyReLU, UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\n\ndef build_generator(img_shape):\n    noise_shape = (100,)\n    \n    model = Sequential()\n    \n    model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n    model.add(Reshape((32, 32, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n    \n    noise = Input(shape=noise_shape)\n    img = model(noise)\n    \n    return Model(noise, img)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.575582Z","iopub.status.idle":"2024-05-23T13:15:07.576041Z","shell.execute_reply.started":"2024-05-23T13:15:07.575795Z","shell.execute_reply":"2024-05-23T13:15:07.575817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator(img_shape):\n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n    img = Input(shape=img_shape)\n    validity = model(img)\n    \n    return Model(img, validity)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.577179Z","iopub.status.idle":"2024-05-23T13:15:07.577601Z","shell.execute_reply.started":"2024-05-23T13:15:07.577390Z","shell.execute_reply":"2024-05-23T13:15:07.577411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Activation\n\n\n\ndef build_gan(generator, discriminator):\n    discriminator.trainable = False\n    gan_input = Input(shape=(100,))\n    generated_image = generator(gan_input)\n    gan_output = discriminator(generated_image)\n    gan = Model(gan_input, gan_output)\n    return gan\n\n# Set image shape and compile models\nimg_shape = (128, 128, 3)\noptimizer = Adam(0.0002, 0.5)\n\n# Build and compile the discriminator\ndiscriminator = build_discriminator(img_shape)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Build the generator\ngenerator = build_generator(img_shape)\n\n# Build and compile the GAN\ngan = build_gan(generator, discriminator)\ngan.compile(loss='binary_crossentropy', optimizer=optimizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.579085Z","iopub.status.idle":"2024-05-23T13:15:07.579516Z","shell.execute_reply.started":"2024-05-23T13:15:07.579303Z","shell.execute_reply":"2024-05-23T13:15:07.579325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Flatten, Dense\n\ndef build_discriminator(input_shape):\n    model = Sequential()\n    model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=input_shape, padding=\"same\"))\n    # Add more layers as needed\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# Example usage:\nimg_shape = (32, 32, 3)  # Replace with your image shape\ndiscriminator = build_discriminator(img_shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.581356Z","iopub.status.idle":"2024-05-23T13:15:07.581793Z","shell.execute_reply.started":"2024-05-23T13:15:07.581581Z","shell.execute_reply":"2024-05-23T13:15:07.581605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Import necessary modules and functions\nfrom keras.datasets import cifar10  # Replace with your dataset\nfrom discriminator import build_discriminator  # Replace with your discriminator model\nfrom generator import build_generator  # Replace with your generator model\nfrom gan import GAN  # Replace with your GAN model\n\n# Define generator, discriminator, and GAN models\ngenerator = build_generator(img_shape)  # Replace img_shape with your image shape\ndiscriminator = build_discriminator(img_shape)  # Replace img_shape with your image shape\ngan = GAN(generator, discriminator)\n\ndef train_gan(epochs, batch_size, save_interval):\n    (X_train, _), (_, _) = cifar10.load_data()  # Replace with your dataset\n    X_train = (X_train - 127.5) / 127.5  # Normalize images to [-1, 1]\n    \n    half_batch = int(batch_size / 2)\n    \n    for epoch in range(epochs):\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        \n        # Select a random half batch of images\n        idx = np.random.randint(0, X_train.shape[0], half_batch)\n        imgs = X_train[idx]\n        \n        noise = np.random.normal(0, 1, (half_batch, 100))\n        gen_imgs = generator.predict(noise)\n        \n        # Train the discriminator\n        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        # ---------------------\n        #  Train Generator\n        # ---------------------\n        \n        noise = np.random.normal(0, 1, (batch_size, 100))\n        \n        valid_y = np.array([1] * batch_size)\n        \n        # Train the generator\n        g_loss = gan.train_on_batch(noise, valid_y)\n        \n        # Print the progress\n        print(f\"{epoch} [D loss: {d_loss[0]}] [D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]\")\n        \n        # If at save interval, save generated image samples\n        if epoch % save_interval == 0:\n            save_imgs(epoch)\n\ndef save_imgs(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, 100))\n    gen_imgs = generator.predict(noise)\n    \n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    \n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n            axs[i,j].axis('off')\n            cnt += 1\n    fig.savefig(f\"gan_images/cifar10_{epoch}.png\")\n    plt.close()\n\n# Training the GAN\ntrain_gan(epochs=10000, batch_size=64, save_interval=200)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.584189Z","iopub.status.idle":"2024-05-23T13:15:07.584631Z","shell.execute_reply.started":"2024-05-23T13:15:07.584419Z","shell.execute_reply":"2024-05-23T13:15:07.584442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reconstruct_image(image_path, generator, image_size=(128, 128)):\n    # Load and preprocess the image\n    image = np.array(convert_to_ela_image(image_path, 91).resize(image_size)).flatten() / 255.0\n    image = image.reshape(1, 128, 128, 3)\n    \n    # Generate noise\n    noise = np.random.normal(0, 1, (1, 100))\n    \n    # Generate reconstructed image\n    reconstructed_img = generator.predict(noise)\n    \n    # Rescale images 0 - 1\n    reconstructed_img = 0.5 * reconstructed_img + 0.5\n    \n    plt.figure(figsize=(8, 4))\n    \n    # Display original image\n    plt.subplot(1, 2, 1)\n    img = Image.open(image_path)\n    plt.imshow(img)\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    # Display reconstructed image\n    plt.subplot(1, 2, 2)\n    plt.imshow(reconstructed_img[0])\n    plt.title('Reconstructed Image')\n    plt.axis('off')\n    \n    plt.show()\n\n# Example reconstruction\nsample_image_path = random_sample('../input/casia-dataset/CASIA2/Tp/')\nreconstruct_image(sample_image_path, generator)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T13:15:07.585687Z","iopub.status.idle":"2024-05-23T13:15:07.587036Z","shell.execute_reply.started":"2024-05-23T13:15:07.586714Z","shell.execute_reply":"2024-05-23T13:15:07.586744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}